{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Credit Card Fraud Detection assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGAH2qBR2Bob"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGQz9QyD2Bow"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4T-sbND2Boy"
      },
      "source": [
        "# Description about dataset::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg78J5pM2Bo0"
      },
      "source": [
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "\n",
        "\n",
        "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxvtLqf92Bo1"
      },
      "source": [
        "# WORKFLOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7WXfhdD2Bo2"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables. \n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92%\n",
        "10.Evaluation Step\n",
        "11Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PImIjdcS2Bo4"
      },
      "source": [
        "# Task::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJhs2Tnx2Bo5"
      },
      "source": [
        "## Identify fraudulent credit card transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrCzLtw83Ehd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "## Keras Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "## Accuracy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import seaborn as sns\n",
        "# Oversample with SMOTE and random undersample for imbalanced dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOysTNNCtrtk"
      },
      "source": [
        "## 1) Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIlQ8ddxsK43"
      },
      "source": [
        "df = pd.read_csv('/content/creditcard.csv')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vdhThyCh1IX"
      },
      "source": [
        "# Display Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "1wV3ZFmKh1y-",
        "outputId": "eae4685b-6930-4c8d-b82b-05775ab2ce6a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqVkIESuCjj"
      },
      "source": [
        "## Check Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0_PeugMsK45",
        "outputId": "26a644ea-2c7c-48c1-df59-3bf6915a25cd"
      },
      "source": [
        "df.isnull().sum()  "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB_BPFFRuwU3"
      },
      "source": [
        "## 3) Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GFPbLxdupM9"
      },
      "source": [
        "X=df.drop(['Amount','Time','Class'],axis=1)\n",
        "y=df['Class']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYjNP0tZwp3L"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGMw9IuPwrh1"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5uLW_IQu1O0"
      },
      "source": [
        "##  50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNu7w_wAsK46"
      },
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1)\n",
        "\n",
        " X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSLlu9bU-RtR"
      },
      "source": [
        "## Data is so imbalance so we will use Balancing Technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7trelaDe-w89",
        "outputId": "154aa2b1-58de-4a1d-e48d-0b5a7696fe5d"
      },
      "source": [
        "over = SMOTE()\n",
        "under = RandomUnderSampler()\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "X_train, y_train = pipeline.fit_resample(X_train, y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHJDeaOavD3T"
      },
      "source": [
        "## Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ-KNyrKsK47"
      },
      "source": [
        "loan = Sequential()\n",
        "loan.add(Dense(10, input_shape=(28,), activation='relu')),\n",
        "loan.add(Dropout(0.2)),\n",
        "loan.add(Dense(8, activation='relu')),\n",
        "loan.add(Dropout(0.2)),\n",
        "loan.add(Dense(6, activation='relu')),\n",
        "loan.add(Dropout(0.2)),\n",
        "loan.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_KuVbiL5WnB"
      },
      "source": [
        "## Binary So Using Binary Crossentropy Loss and Optimzer = Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvFg-6zm2Bo-"
      },
      "source": [
        "loan.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD7nEA5R5h9B"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt7jhHt32Bo_",
        "outputId": "7f6af56b-2d5d-49c4-b7af-ed8eabec5bfe"
      },
      "source": [
        "history = loan.fit(X_train, y_train, epochs=100, batch_size=5, validation_data=(X_val, y_val))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.2599 - accuracy: 0.8936 - val_loss: 0.0856 - val_accuracy: 0.9817\n",
            "Epoch 2/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1828 - accuracy: 0.9282 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 3/100\n",
            "45482/45482 [==============================] - 60s 1ms/step - loss: 0.1765 - accuracy: 0.9296 - val_loss: 0.1071 - val_accuracy: 0.9771\n",
            "Epoch 4/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1676 - accuracy: 0.9334 - val_loss: 0.0931 - val_accuracy: 0.9862\n",
            "Epoch 5/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1634 - accuracy: 0.9351 - val_loss: 0.0831 - val_accuracy: 0.9831\n",
            "Epoch 6/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1611 - accuracy: 0.9346 - val_loss: 0.1406 - val_accuracy: 0.9664\n",
            "Epoch 7/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1598 - accuracy: 0.9349 - val_loss: 0.0558 - val_accuracy: 0.9883\n",
            "Epoch 8/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1576 - accuracy: 0.9348 - val_loss: 0.0612 - val_accuracy: 0.9839\n",
            "Epoch 9/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1560 - accuracy: 0.9352 - val_loss: 0.1878 - val_accuracy: 0.9185\n",
            "Epoch 10/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1522 - accuracy: 0.9367 - val_loss: 0.0814 - val_accuracy: 0.9816\n",
            "Epoch 11/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1537 - accuracy: 0.9369 - val_loss: 0.0731 - val_accuracy: 0.9805\n",
            "Epoch 12/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1523 - accuracy: 0.9355 - val_loss: 0.1149 - val_accuracy: 0.9678\n",
            "Epoch 13/100\n",
            "45482/45482 [==============================] - 60s 1ms/step - loss: 0.1485 - accuracy: 0.9374 - val_loss: 0.0816 - val_accuracy: 0.9815\n",
            "Epoch 14/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1457 - accuracy: 0.9381 - val_loss: 0.0497 - val_accuracy: 0.9896\n",
            "Epoch 15/100\n",
            "45482/45482 [==============================] - 60s 1ms/step - loss: 0.1457 - accuracy: 0.9372 - val_loss: 0.0497 - val_accuracy: 0.9876\n",
            "Epoch 16/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1435 - accuracy: 0.9391 - val_loss: 0.0652 - val_accuracy: 0.9824\n",
            "Epoch 17/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1392 - accuracy: 0.9406 - val_loss: 0.0449 - val_accuracy: 0.9862\n",
            "Epoch 18/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1414 - accuracy: 0.9394 - val_loss: 0.0690 - val_accuracy: 0.9827\n",
            "Epoch 19/100\n",
            "45482/45482 [==============================] - 60s 1ms/step - loss: 0.1361 - accuracy: 0.9418 - val_loss: 0.1408 - val_accuracy: 0.9488\n",
            "Epoch 20/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1394 - accuracy: 0.9409 - val_loss: 0.0545 - val_accuracy: 0.9768\n",
            "Epoch 21/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1373 - accuracy: 0.9410 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 22/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1350 - accuracy: 0.9417 - val_loss: 0.0926 - val_accuracy: 0.9764\n",
            "Epoch 23/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1335 - accuracy: 0.9421 - val_loss: 0.0609 - val_accuracy: 0.9793\n",
            "Epoch 24/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1341 - accuracy: 0.9433 - val_loss: 0.0371 - val_accuracy: 0.9886\n",
            "Epoch 25/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1314 - accuracy: 0.9438 - val_loss: 0.0946 - val_accuracy: 0.9612\n",
            "Epoch 26/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1338 - accuracy: 0.9428 - val_loss: 0.0743 - val_accuracy: 0.9728\n",
            "Epoch 27/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1331 - accuracy: 0.9427 - val_loss: 0.0749 - val_accuracy: 0.9749\n",
            "Epoch 28/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1320 - accuracy: 0.9429 - val_loss: 0.0625 - val_accuracy: 0.9807\n",
            "Epoch 29/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1299 - accuracy: 0.9441 - val_loss: 0.0794 - val_accuracy: 0.9721\n",
            "Epoch 30/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1334 - accuracy: 0.9433 - val_loss: 0.0923 - val_accuracy: 0.9666\n",
            "Epoch 31/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1197 - val_accuracy: 0.9558\n",
            "Epoch 32/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1292 - accuracy: 0.9449 - val_loss: 0.0541 - val_accuracy: 0.9802\n",
            "Epoch 33/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1317 - accuracy: 0.9437 - val_loss: 0.0623 - val_accuracy: 0.9651\n",
            "Epoch 34/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1304 - accuracy: 0.9441 - val_loss: 0.1310 - val_accuracy: 0.9488\n",
            "Epoch 35/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1270 - accuracy: 0.9457 - val_loss: 0.0907 - val_accuracy: 0.9648\n",
            "Epoch 36/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1295 - accuracy: 0.9435 - val_loss: 0.0818 - val_accuracy: 0.9738\n",
            "Epoch 37/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1263 - accuracy: 0.9458 - val_loss: 0.0783 - val_accuracy: 0.9768\n",
            "Epoch 38/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1290 - accuracy: 0.9450 - val_loss: 0.0823 - val_accuracy: 0.9644\n",
            "Epoch 39/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1272 - accuracy: 0.9464 - val_loss: 0.0591 - val_accuracy: 0.9807\n",
            "Epoch 40/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1268 - accuracy: 0.9445 - val_loss: 0.1045 - val_accuracy: 0.9617\n",
            "Epoch 41/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1275 - accuracy: 0.9451 - val_loss: 0.0689 - val_accuracy: 0.9737\n",
            "Epoch 42/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1250 - accuracy: 0.9466 - val_loss: 0.0995 - val_accuracy: 0.9500\n",
            "Epoch 43/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1242 - accuracy: 0.9464 - val_loss: 0.1013 - val_accuracy: 0.9548\n",
            "Epoch 44/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1269 - accuracy: 0.9457 - val_loss: 0.0613 - val_accuracy: 0.9754\n",
            "Epoch 45/100\n",
            "45482/45482 [==============================] - 61s 1ms/step - loss: 0.1237 - accuracy: 0.9467 - val_loss: 0.0720 - val_accuracy: 0.9728\n",
            "Epoch 46/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1248 - accuracy: 0.9477 - val_loss: 0.0831 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1285 - accuracy: 0.9454 - val_loss: 0.0349 - val_accuracy: 0.9861\n",
            "Epoch 48/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1267 - accuracy: 0.9457 - val_loss: 0.0634 - val_accuracy: 0.9813\n",
            "Epoch 49/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1237 - accuracy: 0.9478 - val_loss: 0.0510 - val_accuracy: 0.9808\n",
            "Epoch 50/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1218 - accuracy: 0.9476 - val_loss: 0.0527 - val_accuracy: 0.9772\n",
            "Epoch 51/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1215 - accuracy: 0.9486 - val_loss: 0.0548 - val_accuracy: 0.9836\n",
            "Epoch 52/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1251 - accuracy: 0.9468 - val_loss: 0.0372 - val_accuracy: 0.9906\n",
            "Epoch 53/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1226 - accuracy: 0.9469 - val_loss: 0.0584 - val_accuracy: 0.9813\n",
            "Epoch 54/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1220 - accuracy: 0.9474 - val_loss: 0.0450 - val_accuracy: 0.9819\n",
            "Epoch 55/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1227 - accuracy: 0.9476 - val_loss: 0.0478 - val_accuracy: 0.9801\n",
            "Epoch 56/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1239 - accuracy: 0.9475 - val_loss: 0.0803 - val_accuracy: 0.9631\n",
            "Epoch 57/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1231 - accuracy: 0.9472 - val_loss: 0.0822 - val_accuracy: 0.9662\n",
            "Epoch 58/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1311 - accuracy: 0.9390 - val_loss: 0.0759 - val_accuracy: 0.9661\n",
            "Epoch 59/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1210 - accuracy: 0.9479 - val_loss: 0.0539 - val_accuracy: 0.9780\n",
            "Epoch 60/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1211 - accuracy: 0.9493 - val_loss: 0.1273 - val_accuracy: 0.9386\n",
            "Epoch 61/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1225 - accuracy: 0.9468 - val_loss: 0.0765 - val_accuracy: 0.9667\n",
            "Epoch 62/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1227 - accuracy: 0.9462 - val_loss: 0.0760 - val_accuracy: 0.9655\n",
            "Epoch 63/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1201 - accuracy: 0.9493 - val_loss: 0.0740 - val_accuracy: 0.9697\n",
            "Epoch 64/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1198 - accuracy: 0.9485 - val_loss: 0.0565 - val_accuracy: 0.9776\n",
            "Epoch 65/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1236 - accuracy: 0.9474 - val_loss: 0.0449 - val_accuracy: 0.9810\n",
            "Epoch 66/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1195 - accuracy: 0.9480 - val_loss: 0.0501 - val_accuracy: 0.9778\n",
            "Epoch 67/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1215 - accuracy: 0.9481 - val_loss: 0.0493 - val_accuracy: 0.9785\n",
            "Epoch 68/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1222 - accuracy: 0.9478 - val_loss: 0.0588 - val_accuracy: 0.9698\n",
            "Epoch 69/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1257 - accuracy: 0.9439 - val_loss: 0.0775 - val_accuracy: 0.9649\n",
            "Epoch 70/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1193 - accuracy: 0.9493 - val_loss: 0.0589 - val_accuracy: 0.9742\n",
            "Epoch 71/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1221 - accuracy: 0.9474 - val_loss: 0.1093 - val_accuracy: 0.9598\n",
            "Epoch 72/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1202 - accuracy: 0.9481 - val_loss: 0.0464 - val_accuracy: 0.9836\n",
            "Epoch 73/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1219 - accuracy: 0.9481 - val_loss: 0.0650 - val_accuracy: 0.9704\n",
            "Epoch 74/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1169 - accuracy: 0.9499 - val_loss: 0.0877 - val_accuracy: 0.9600\n",
            "Epoch 75/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1197 - accuracy: 0.9480 - val_loss: 0.1058 - val_accuracy: 0.9543\n",
            "Epoch 76/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1225 - accuracy: 0.9485 - val_loss: 0.1006 - val_accuracy: 0.9560\n",
            "Epoch 77/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1186 - accuracy: 0.9499 - val_loss: 0.0556 - val_accuracy: 0.9821\n",
            "Epoch 78/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1187 - accuracy: 0.9495 - val_loss: 0.0578 - val_accuracy: 0.9709\n",
            "Epoch 79/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1190 - accuracy: 0.9489 - val_loss: 0.0623 - val_accuracy: 0.9715\n",
            "Epoch 80/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1189 - accuracy: 0.9490 - val_loss: 0.0639 - val_accuracy: 0.9702\n",
            "Epoch 81/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1200 - accuracy: 0.9498 - val_loss: 0.0707 - val_accuracy: 0.9754\n",
            "Epoch 82/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1173 - accuracy: 0.9508 - val_loss: 0.0847 - val_accuracy: 0.9625\n",
            "Epoch 83/100\n",
            "45482/45482 [==============================] - 62s 1ms/step - loss: 0.1186 - accuracy: 0.9505 - val_loss: 0.0673 - val_accuracy: 0.9701\n",
            "Epoch 84/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1205 - accuracy: 0.9490 - val_loss: 0.1073 - val_accuracy: 0.9569\n",
            "Epoch 85/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1187 - accuracy: 0.9492 - val_loss: 0.0911 - val_accuracy: 0.9540\n",
            "Epoch 86/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1200 - accuracy: 0.9491 - val_loss: 0.0515 - val_accuracy: 0.9737\n",
            "Epoch 87/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1161 - accuracy: 0.9502 - val_loss: 0.0683 - val_accuracy: 0.9694\n",
            "Epoch 88/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1205 - accuracy: 0.9485 - val_loss: 0.0508 - val_accuracy: 0.9772\n",
            "Epoch 89/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1195 - accuracy: 0.9494 - val_loss: 0.0645 - val_accuracy: 0.9647\n",
            "Epoch 90/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1173 - accuracy: 0.9478 - val_loss: 0.0399 - val_accuracy: 0.9778\n",
            "Epoch 91/100\n",
            "45482/45482 [==============================] - 63s 1ms/step - loss: 0.1177 - accuracy: 0.9493 - val_loss: 0.0602 - val_accuracy: 0.9644\n",
            "Epoch 92/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1169 - accuracy: 0.9499 - val_loss: 0.0424 - val_accuracy: 0.9829\n",
            "Epoch 93/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1170 - accuracy: 0.9496 - val_loss: 0.0724 - val_accuracy: 0.9729\n",
            "Epoch 94/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1183 - accuracy: 0.9510 - val_loss: 0.0692 - val_accuracy: 0.9689\n",
            "Epoch 95/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1169 - accuracy: 0.9495 - val_loss: 0.0613 - val_accuracy: 0.9747\n",
            "Epoch 96/100\n",
            "45482/45482 [==============================] - 65s 1ms/step - loss: 0.1156 - accuracy: 0.9494 - val_loss: 0.0591 - val_accuracy: 0.9715\n",
            "Epoch 97/100\n",
            "45482/45482 [==============================] - 65s 1ms/step - loss: 0.1220 - accuracy: 0.9486 - val_loss: 0.0503 - val_accuracy: 0.9747\n",
            "Epoch 98/100\n",
            "45482/45482 [==============================] - 64s 1ms/step - loss: 0.1177 - accuracy: 0.9493 - val_loss: 0.0579 - val_accuracy: 0.9719\n",
            "Epoch 99/100\n",
            "45482/45482 [==============================] - 65s 1ms/step - loss: 0.1189 - accuracy: 0.9489 - val_loss: 0.0585 - val_accuracy: 0.9679\n",
            "Epoch 100/100\n",
            "45482/45482 [==============================] - 65s 1ms/step - loss: 0.1197 - accuracy: 0.9467 - val_loss: 0.0589 - val_accuracy: 0.9748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBtpA70zy2KM"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc53IW7-qg2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb09a95-9030-4732-8ff1-077f76dc0f9a"
      },
      "source": [
        "pred = loan.predict_classes(X_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AboMChTfy05U"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "## 99% Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7824SHI9zwIL",
        "outputId": "78519a3e-b285-4938-f936-215b7e1be816"
      },
      "source": [
        "results = loan.evaluate(X_test,y_test)\n",
        "print('Test accuracy: ', results[1]*100)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4451/4451 [==============================] - 5s 1ms/step - loss: 0.0608 - accuracy: 0.9745\n",
            "Test accuracy:  97.44670391082764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "24pg2FEqqg2r",
        "outputId": "382c8c6b-a670-4d01-b78b-8efea7458c96"
      },
      "source": [
        "# Creating the confusion matrix:\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "# Visualization:\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax, cmap='BrBG')\n",
        "plt.title('NN Classification Confusion Matrix')\n",
        "plt.xlabel('y_pred')\n",
        "plt.ylabel('y_test')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfZ8YtXzqg2s",
        "outputId": "960daf4a-86c4-4886-da98-8eb674fcc7d6"
      },
      "source": [
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99    142177\n",
            "           1       0.05      0.88      0.10       227\n",
            "\n",
            "    accuracy                           0.97    142404\n",
            "   macro avg       0.53      0.93      0.54    142404\n",
            "weighted avg       1.00      0.97      0.99    142404\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}